# üß¨ NEET Biology Concept Explainer  
### Retrieval-Augmented Generation (RAG) System using NCERT

---

## üìå Project Overview

This project is a **NEET Biology Concept Explainer** built using a **Retrieval-Augmented Generation (RAG)** architecture.  
It answers Biology questions **strictly based on NCERT Class XI & XII Biology textbooks**, rewritten in **simple, student-friendly language** suitable for NEET preparation.

Unlike generic LLM chatbots, this system:
- Avoids hallucination *(by generating answers only from semantically retrieved NCERT content using Hugging Face embeddings and FAISS, with strict prompt constraints and no external knowledge access)*  
- Avoids out-of-syllabus content  
- Avoids copying NCERT sentences  
- Produces **original, exam-oriented explanations**

The application is implemented as a **full-stack AI system** using:
- **FastAPI** (backend + frontend serving)
- **FAISS** (vector similarity search)
- **Hugging Face Transformer encoders** (sentence embeddings)
- **LLaMA-3 via Ollama** (answer generation)

---

## üéØ Problem Statement

NEET aspirants often face:
- Dense NCERT explanations  
- Online answers that go beyond syllabus  
- Hallucinated or plagiarized responses from LLMs  

This project solves the problem by:
- Grounding all answers strictly in NCERT PDFs  
- Using semantic retrieval instead of guessing  
- Rewriting concepts in **clear, NEET-focused language**

---

## üß† RAG SYSTEM ‚Äì BUILD FLOW (Knowledge Base Construction)

This flow represents the **offline / one-time build process** of the RAG system.

Start
‚Üì
Collect NCERT Biology PDFs
(Class XI & Class XII)
‚Üì
PDF Document Loader
(Text Extraction)
‚Üì
Text Cleaning & Normalization
‚Üì
Text Chunking
(semantic, overlapping chunks)
‚Üì
Hugging Face Transformer-based
Sentence Embeddings
(chunks ‚Üí dense vectors)
‚Üì
Vector Normalization
(for cosine similarity)
‚Üì
FAISS Vector Index Creation
(Cosine Similarity Search)
‚Üì
Persist Artifacts to Disk
(chunks.pkl, embeddings.npy, faiss.index)
‚Üì
RAG Knowledge Base Ready
‚Üì
End

‚úî This pipeline runs **once during build time**, not during query time.

---

## üß† RAG QUERY-TIME FLOW (Runtime Inference)
User Question
‚Üì
Query Embedding
(Hugging Face Transformer Encoder)
‚Üì
FAISS Cosine Similarity Search
‚Üì
Top-K Relevant NCERT Chunks
‚Üì
Rule-Constrained Prompt Engineering
‚Üì
LLaMA-3 (Transformer Decoder via Ollama)
‚Üì
NEET-Style Concept Explanation


---

## üß© Core Techniques Used

### 1Ô∏è‚É£ Retrieval-Augmented Generation (RAG)
- Combines retrieval with generation  
- Keeps LLM responses grounded in NCERT content  
- Core mechanism for hallucination control  

### 2Ô∏è‚É£ NCERT PDF Processing
- Structured loading of NCERT Biology PDFs  
- Page-wise text extraction  
- NCERT used as the **single source of truth**  

### 3Ô∏è‚É£ Text Chunking Strategy
- Text split into **semantic overlapping chunks**  
- Preserves conceptual continuity  
- Optimized for biology concepts  

### 4Ô∏è‚É£ Hugging Face Transformer-based Sentence Embeddings
- Each NCERT chunk converted into dense vectors  
- Implemented using **Hugging Face Transformer encoder models**  
- Captures semantic meaning rather than keywords  
- Handles paraphrased and indirect questions  

### 5Ô∏è‚É£ Cosine Similarity Search using FAISS
- Embeddings normalized  
- FAISS performs **cosine similarity-based semantic retrieval**  
- Retrieves the most relevant NCERT chunks  

> Cosine similarity is used because it compares semantic direction rather than magnitude.

### 6Ô∏è‚É£ Prompt Engineering (Critical Design)
Strict constraints enforced:
- NCERT content used only for understanding  
- No sentence copying  
- Simple NEET-level language  
- 4‚Äì6 concise sentences  
- Focus on definition and key functions  

### 7Ô∏è‚É£ LLaMA-3 via Ollama (Transformer Decoder)
- Decoder-only Transformer model  
- Executed locally using **Ollama**  
- No Hugging Face inference pipeline used  
- Offline, cost-free inference  
- Used strictly for explanation and rewriting  

---

## üö´ How the System Avoids Hallucination

- Answers are generated **only after retrieving semantically relevant NCERT chunks**
- Retrieval uses **Hugging Face embeddings + FAISS cosine similarity**
- The LLM never answers from its own knowledge
- No internet access or external tools during generation
- Prompt rules strictly limit scope and wording

---

## üåê Backend (FastAPI)

### Features
- FastAPI-based **HTTP inference endpoint**
- Serves frontend UI directly
- Handles long-running LLM inference
- Clear separation of build-time and query-time logic

### Endpoints

| Endpoint | Purpose |
|--------|--------|
| `/` | Frontend UI |
| `/concept` | POST ‚Äì AI inference endpoint |
| `/docs` | Swagger UI (testing only) |
| `/health` | Health check |

---

## üé® Frontend
- HTML, CSS, JavaScript  
- Served directly by FastAPI  
- Uses Fetch API to communicate with backend  

---

## üõ†Ô∏è Tools & Technologies

### Programming & Frameworks
- Python  
- FastAPI  
- JavaScript  
- HTML, CSS  

### AI & NLP
- Hugging Face Transformer Encoder Models  
- Sentence Embeddings  
- FAISS  
- Cosine Similarity Search  
- Retrieval-Augmented Generation (RAG)  
- Prompt Engineering  
- LLaMA-3 (via Ollama ‚Äì Transformer Decoder)  

### Data & Storage
- FAISS index  
- NumPy  
- Pickle  

---

## üöÄ How to Run

```bash
venv\Scripts\activate
python -m uvicorn backend.main:app --host 127.0.0.1 --port 8007

http://localhost:8007


